{
    "model": "gguf",
    "inference_api": {
        "hf_url": "bigcode/starcoder2-15b",
        "hf_token": "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"
    },
    "bitsandbytes":{
        "hf_url": "bigcode/starcoder2-15b",
        "quantization": "4bit"
    },
    "gptq":{
        "hf_url":"TechxGenus/starcoder2-15b-GPTQ"
    },
    "gguf":{
        "hf_url": "mradermacher/Qwen2.5-14B-i1-GGUF",
        "filename": "Qwen2.5-14B.i1-Q4_K_S.gguf",
        "offline": false,
        "context_size": 2048
    },
    "cache":{
        "enabled": true,
        "filename": null
    }
}